{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "provenance": [],
      "authorship_tag": "ABX9TyMvzM7fZDKC5H7VUChW0riu",
      "include_colab_link": true
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "language_info": {
      "name": "python"
    }
  },
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "view-in-github",
        "colab_type": "text"
      },
      "source": [
        "<a href=\"https://colab.research.google.com/github/RashmikaReddy/Quora-Question-Similarity/blob/main/TFIDF_Quora_Question_Similarity.ipynb\" target=\"_parent\"><img src=\"https://colab.research.google.com/assets/colab-badge.svg\" alt=\"Open In Colab\"/></a>"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "n56HGe5P3nx4"
      },
      "outputs": [],
      "source": [
        "import pandas as pd\n",
        "import matplotlib.pyplot as plt\n",
        "import re\n",
        "import time\n",
        "import warnings\n",
        "import numpy as np\n",
        "from nltk.corpus import stopwords\n",
        "from sklearn.preprocessing import normalize\n",
        "from sklearn.feature_extraction.text import CountVectorizer\n",
        "from sklearn.feature_extraction.text import TfidfVectorizer\n",
        "warnings.filterwarnings(\"ignore\")\n",
        "import sys\n",
        "import os \n",
        "import pandas as pd\n",
        "import numpy as np\n",
        "from tqdm import tqdm\n",
        "\n",
        "# exctract word2vec vectors\n",
        "# https://github.com/explosion/spaCy/issues/1721\n",
        "# http://landinghub.visualstudio.com/visual-cpp-build-tools\n",
        "import spacy"
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "from google.colab import drive\n",
        "drive.mount('/content/drive')"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "XEp8jPrnVK5T",
        "outputId": "bf2ad3ef-91ca-4bec-94e4-215a09865e93"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Drive already mounted at /content/drive; to attempt to forcibly remount, call drive.mount(\"/content/drive\", force_remount=True).\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "df_tfidf = pd.read_csv(\"/content/drive/MyDrive/QuoraQuestionSimilarity/questions.csv\")"
      ],
      "metadata": {
        "id": "BHGu8EHN3xV-"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "import seaborn as sns\n",
        "%matplotlib inline\n",
        "df_tfidf.dropna(axis=0, inplace=True)\n",
        "df_tfidf.groupby(\"is_duplicate\")['id'].count().plot.bar()"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 295
        },
        "id": "UTXKUrtpVErH",
        "outputId": "7a559aff-c541-4b1b-a3bf-ef9b0bfe6655"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "<matplotlib.axes._subplots.AxesSubplot at 0x7f3ebeefb430>"
            ]
          },
          "metadata": {},
          "execution_count": 29
        },
        {
          "output_type": "display_data",
          "data": {
            "text/plain": [
              "<Figure size 432x288 with 1 Axes>"
            ],
            "image/png": "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\n"
          },
          "metadata": {
            "needs_background": "light"
          }
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "df_tfidf.drop(['id', 'qid1', 'qid2'], axis=1, inplace=True)\n",
        "a = 0 \n",
        "for i in range(a,a+10):\n",
        "    print(df_tfidf.question1[i])\n",
        "    print(df_tfidf.question2[i])\n",
        "    print()"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "eApYCULdV9yy",
        "outputId": "6b160257-60c9-4d62-e4b0-b3498e3a641f"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "What is the step by step guide to invest in share market in india?\n",
            "What is the step by step guide to invest in share market?\n",
            "\n",
            "What is the story of Kohinoor (Koh-i-Noor) Diamond?\n",
            "What would happen if the Indian government stole the Kohinoor (Koh-i-Noor) diamond back?\n",
            "\n",
            "How can I increase the speed of my internet connection while using a VPN?\n",
            "How can Internet speed be increased by hacking through DNS?\n",
            "\n",
            "Why am I mentally very lonely? How can I solve it?\n",
            "Find the remainder when [math]23^{24}[/math] is divided by 24,23?\n",
            "\n",
            "Which one dissolve in water quikly sugar, salt, methane and carbon di oxide?\n",
            "Which fish would survive in salt water?\n",
            "\n",
            "Astrology: I am a Capricorn Sun Cap moon and cap rising...what does that say about me?\n",
            "I'm a triple Capricorn (Sun, Moon and ascendant in Capricorn) What does this say about me?\n",
            "\n",
            "Should I buy tiago?\n",
            "What keeps childern active and far from phone and video games?\n",
            "\n",
            "How can I be a good geologist?\n",
            "What should I do to be a great geologist?\n",
            "\n",
            "When do you use シ instead of し?\n",
            "When do you use \"&\" instead of \"and\"?\n",
            "\n",
            "Motorola (company): Can I hack my Charter Motorolla DCX3400?\n",
            "How do I hack Motorola DCX3400 for free internet?\n",
            "\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "SPECIAL_TOKENS = {\n",
        "    'quoted': 'quoted_item',\n",
        "    'non-ascii': 'non_ascii_word',\n",
        "    'undefined': 'something'\n",
        "}\n",
        "\n",
        "def clean(text, stem_words=True):\n",
        "    import re\n",
        "    from string import punctuation\n",
        "    from nltk.stem import SnowballStemmer\n",
        "    from nltk.corpus import stopwords\n",
        "    \n",
        "    def pad_str(s):\n",
        "        return ' '+s+' '\n",
        "    \n",
        "    if pd.isnull(text):\n",
        "        return ''\n",
        "\n",
        "#    stops = set(stopwords.words(\"english\"))\n",
        "    # Clean the text, with the option to stem words.\n",
        "    \n",
        "    # Empty question\n",
        "    \n",
        "    if type(text) != str or text=='':\n",
        "        return ''\n",
        "\n",
        "    # Clean the text\n",
        "    text = re.sub(\"\\'s\", \" \", text) # we have cases like \"Sam is\" or \"Sam's\" (i.e. his) these two cases aren't separable, I choose to compromise are kill \"'s\" directly\n",
        "    text = re.sub(\" whats \", \" what is \", text, flags=re.IGNORECASE)\n",
        "    text = re.sub(\"\\'ve\", \" have \", text)\n",
        "    text = re.sub(\"can't\", \"can not\", text)\n",
        "    text = re.sub(\"n't\", \" not \", text)\n",
        "    text = re.sub(\"i'm\", \"i am\", text, flags=re.IGNORECASE)\n",
        "    text = re.sub(\"\\'re\", \" are \", text)\n",
        "    text = re.sub(\"\\'d\", \" would \", text)\n",
        "    text = re.sub(\"\\'ll\", \" will \", text)\n",
        "    text = re.sub(\"e\\.g\\.\", \" eg \", text, flags=re.IGNORECASE)\n",
        "    text = re.sub(\"b\\.g\\.\", \" bg \", text, flags=re.IGNORECASE)\n",
        "    text = re.sub(\"(\\d+)(kK)\", \" \\g<1>000 \", text)\n",
        "    text = re.sub(\"e-mail\", \" email \", text, flags=re.IGNORECASE)\n",
        "    text = re.sub(\"(the[\\s]+|The[\\s]+)?U\\.S\\.A\\.\", \" America \", text, flags=re.IGNORECASE)\n",
        "    text = re.sub(\"(the[\\s]+|The[\\s]+)?United State(s)?\", \" America \", text, flags=re.IGNORECASE)\n",
        "    text = re.sub(\"\\(s\\)\", \" \", text, flags=re.IGNORECASE)\n",
        "    text = re.sub(\"[c-fC-F]\\:\\/\", \" disk \", text)\n",
        "    \n",
        "    # remove comma between numbers, i.e. 15,000 -> 15000\n",
        "    \n",
        "    text = re.sub('(?<=[0-9])\\,(?=[0-9])', \"\", text)\n",
        "    \n",
        "#     # all numbers should separate from words, this is too aggressive\n",
        "    \n",
        "#     def pad_number(pattern):\n",
        "#         matched_string = pattern.group(0)\n",
        "#         return pad_str(matched_string)\n",
        "#     text = re.sub('[0-9]+', pad_number, text)\n",
        "    \n",
        "    # add padding to punctuations and special chars, we still need them later\n",
        "    \n",
        "    text = re.sub('\\$', \" dollar \", text)\n",
        "    text = re.sub('\\%', \" percent \", text)\n",
        "    text = re.sub('\\&', \" and \", text)\n",
        "    \n",
        "#    def pad_pattern(pattern):\n",
        "#        matched_string = pattern.group(0)\n",
        "#       return pad_str(matched_string)\n",
        "#    text = re.sub('[\\!\\?\\@\\^\\+\\*\\/\\,\\~\\|\\`\\=\\:\\;\\.\\#\\\\\\]', pad_pattern, text) \n",
        "        \n",
        "    text = re.sub('[^\\x00-\\x7F]+', pad_str(SPECIAL_TOKENS['non-ascii']), text) # replace non-ascii word with special word\n",
        "    \n",
        "    # indian dollar\n",
        "    \n",
        "    text = re.sub(\"(?<=[0-9])rs \", \" rs \", text, flags=re.IGNORECASE)\n",
        "    text = re.sub(\" rs(?=[0-9])\", \" rs \", text, flags=re.IGNORECASE)\n",
        "    \n",
        "    # clean text rules get from : https://www.kaggle.com/currie32/the-importance-of-cleaning-text\n",
        "    text = re.sub(r\" (the[\\s]+|The[\\s]+)?US(A)? \", \" America \", text)\n",
        "    text = re.sub(r\" UK \", \" England \", text, flags=re.IGNORECASE)\n",
        "    text = re.sub(r\" india \", \" India \", text)\n",
        "    text = re.sub(r\" switzerland \", \" Switzerland \", text)\n",
        "    text = re.sub(r\" china \", \" China \", text)\n",
        "    text = re.sub(r\" chinese \", \" Chinese \", text) \n",
        "    text = re.sub(r\" imrovement \", \" improvement \", text, flags=re.IGNORECASE)\n",
        "    text = re.sub(r\" intially \", \" initially \", text, flags=re.IGNORECASE)\n",
        "    text = re.sub(r\" quora \", \" Quora \", text, flags=re.IGNORECASE)\n",
        "    text = re.sub(r\" dms \", \" direct messages \", text, flags=re.IGNORECASE)  \n",
        "    text = re.sub(r\" demonitization \", \" demonetization \", text, flags=re.IGNORECASE) \n",
        "    text = re.sub(r\" actived \", \" active \", text, flags=re.IGNORECASE)\n",
        "    text = re.sub(r\" kms \", \" kilometers \", text, flags=re.IGNORECASE)\n",
        "    text = re.sub(r\" cs \", \" computer science \", text, flags=re.IGNORECASE) \n",
        "    text = re.sub(r\" upvote\", \" up vote\", text, flags=re.IGNORECASE)\n",
        "    text = re.sub(r\" iPhone \", \" phone \", text, flags=re.IGNORECASE)\n",
        "    text = re.sub(r\" \\0rs \", \" rs \", text, flags=re.IGNORECASE)\n",
        "    text = re.sub(r\" calender \", \" calendar \", text, flags=re.IGNORECASE)\n",
        "    text = re.sub(r\" ios \", \" operating system \", text, flags=re.IGNORECASE)\n",
        "    text = re.sub(r\" gps \", \" GPS \", text, flags=re.IGNORECASE)\n",
        "    text = re.sub(r\" gst \", \" GST \", text, flags=re.IGNORECASE)\n",
        "    text = re.sub(r\" programing \", \" programming \", text, flags=re.IGNORECASE)\n",
        "    text = re.sub(r\" bestfriend \", \" best friend \", text, flags=re.IGNORECASE)\n",
        "    text = re.sub(r\" dna \", \" DNA \", text, flags=re.IGNORECASE)\n",
        "    text = re.sub(r\" III \", \" 3 \", text)\n",
        "    text = re.sub(r\" banglore \", \" Banglore \", text, flags=re.IGNORECASE)\n",
        "    text = re.sub(r\" J K \", \" JK \", text, flags=re.IGNORECASE)\n",
        "    text = re.sub(r\" J\\.K\\. \", \" JK \", text, flags=re.IGNORECASE)\n",
        "    \n",
        "    # replace the float numbers with a random number, it will be parsed as number afterward, and also been replaced with word \"number\"\n",
        "    \n",
        "    text = re.sub('[0-9]+\\.[0-9]+', \" 87 \", text)\n",
        "  \n",
        "    \n",
        "    # Remove punctuation from text\n",
        "    text = ''.join([c for c in text if c not in punctuation]).lower()\n",
        "       # Return a list of words\n",
        "    return text\n",
        "    \n",
        "df_tfidf['question1'] = df_tfidf['question1'].apply(clean)\n",
        "df_tfidf['question2'] = df_tfidf['question2'].apply(clean)"
      ],
      "metadata": {
        "id": "81DhbJ7uWsv7"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "a = 0 \n",
        "for i in range(a,a+10):\n",
        "    print(df_tfidf.question1[i])\n",
        "    print(df_tfidf.question2[i])\n",
        "    print()"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "J-cUOG__50gC",
        "outputId": "5b24a5d0-a2e6-45a8-9be6-7b37eb1c9c32"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "what is the step by step guide to invest in share market in india\n",
            "what is the step by step guide to invest in share market\n",
            "\n",
            "what is the story of kohinoor kohinoor diamond\n",
            "what would happen if the indian government stole the kohinoor kohinoor diamond back\n",
            "\n",
            "how can i increase the speed of my internet connection while using a vpn\n",
            "how can internet speed be increased by hacking through dns\n",
            "\n",
            "why am i mentally very lonely how can i solve it\n",
            "find the remainder when math2324math is divided by 2423\n",
            "\n",
            "which one dissolve in water quikly sugar salt methane and carbon di oxide\n",
            "which fish would survive in salt water\n",
            "\n",
            "astrology i am a capricorn sun cap moon and cap risingwhat does that say about me\n",
            "i am a triple capricorn sun moon and ascendant in capricorn what does this say about me\n",
            "\n",
            "should i buy tiago\n",
            "what keeps childern active and far from phone and video games\n",
            "\n",
            "how can i be a good geologist\n",
            "what should i do to be a great geologist\n",
            "\n",
            "when do you use  nonasciiword  instead of  nonasciiword \n",
            "when do you use  and  instead of and\n",
            "\n",
            "motorola company can i hack my charter motorolla dcx3400\n",
            "how do i hack motorola dcx3400 for free internet\n",
            "\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "#Bag of Words and XGB model on BOW\n",
        "count_vect = CountVectorizer(analyzer='word', token_pattern=r'\\w{1,}')\n",
        "count_vect.fit(pd.concat((df_tfidf['question1'],df_tfidf['question2'])).unique())\n",
        "trainq1_trans = count_vect.transform(df_tfidf['question1'].values)\n",
        "trainq2_trans = count_vect.transform(df_tfidf['question2'].values)\n",
        "labels = df_tfidf['is_duplicate'].values\n"
      ],
      "metadata": {
        "id": "rEQvvn1J6Lrc"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "trainq1_trans"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "ifJoCdaj9_vh",
        "outputId": "66c32c18-3ba1-48e2-c7de-fd0f4a67c9ba"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "<404348x105112 sparse matrix of type '<class 'numpy.int64'>'\n",
              "\twith 4221125 stored elements in Compressed Sparse Row format>"
            ]
          },
          "metadata": {},
          "execution_count": 34
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "import scipy\n",
        "from scipy.sparse import hstack\n",
        "X = scipy.sparse.hstack((trainq1_trans,trainq2_trans))\n",
        "y = labels"
      ],
      "metadata": {
        "id": "Mma6I4T1_PSe"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "from sklearn.model_selection import train_test_split\n",
        "import xgboost as xgb\n",
        "X_train,X_valid,y_train,y_valid = train_test_split(X,y, test_size = 0.33, random_state = 42)\n",
        "\n",
        "xgb_model = xgb.XGBClassifier(max_depth=50, n_estimators=80, learning_rate=0.1, colsample_bytree=.7, gamma=0, reg_alpha=4, objective='binary:logistic', eta=0.3, silent=1, subsample=0.8).fit(X_train, y_train) \n",
        "xgb_prediction = xgb_model.predict(X_valid)\n",
        "\n"
      ],
      "metadata": {
        "id": "xCuHENHs8qDK"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "from sklearn.metrics import f1_score, classification_report, accuracy_score\n",
        "\n",
        "print('training score:', f1_score(y_train, xgb_model.predict(X_train), average='macro'))\n",
        "print('validation score:', f1_score(y_valid, xgb_model.predict(X_valid), average='macro'))\n",
        "\n",
        "print(classification_report(y_valid, xgb_prediction))"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "y0v7zP-W9KwP",
        "outputId": "d2fe1578-5339-4f90-d358-3f56b6e9e967"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "training score: 0.830410003634199\n",
            "validation score: 0.7614430800746755\n",
            "              precision    recall  f1-score   support\n",
            "\n",
            "           0       0.80      0.90      0.84     84355\n",
            "           1       0.77      0.60      0.68     49080\n",
            "\n",
            "    accuracy                           0.79    133435\n",
            "   macro avg       0.79      0.75      0.76    133435\n",
            "weighted avg       0.79      0.79      0.78    133435\n",
            "\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "#Calculating LogLoss to compare XGB with BOW and XGB with TF-IDF weighted word2vec\n",
        "from sklearn.metrics import accuracy_score, log_loss\n",
        "\n",
        "log_loss_test = log_loss(y_valid, xgb_prediction, eps=1e-15)\n",
        "print(\"log loss is\",log_loss_test)\n"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "wj7WZOwRWL1O",
        "outputId": "4edb2ad5-6714-408f-cf86-ca669b9def78"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "log loss is 9.117285567496445\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "#TF-IDF at word level and XgBoost\n",
        "tfidf_vect = TfidfVectorizer(analyzer='word', token_pattern=r'\\w{1,}', max_features=5000)\n",
        "tfidf_vect.fit(pd.concat((df_tfidf['question1'],df_tfidf['question2'])).unique())\n",
        "trainq1_trans = tfidf_vect.transform(df_tfidf['question1'].values)\n",
        "trainq2_trans = tfidf_vect.transform(df_tfidf['question2'].values)\n",
        "labels = df_tfidf['is_duplicate'].values\n",
        "X = scipy.sparse.hstack((trainq1_trans,trainq2_trans))\n",
        "y = labels\n",
        "X_train,X_valid,y_train,y_valid = train_test_split(X,y, test_size = 0.33, random_state = 42)\n",
        "\n",
        "xgb_model_1 = xgb.XGBClassifier(max_depth=50, n_estimators=80, learning_rate=0.1, colsample_bytree=.7, gamma=0, reg_alpha=4, objective='binary:logistic', eta=0.3, silent=1, subsample=0.8).fit(X_train, y_train) \n",
        "xgb_prediction = xgb_model_1.predict(X_valid)\n"
      ],
      "metadata": {
        "id": "hNU23R3fCCxy"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "print('word level tf-idf training score:', f1_score(y_train, xgb_model_1.predict(X_train), average='macro'))\n",
        "print('word level tf-idf validation score:', f1_score(y_valid, xgb_model_1.predict(X_valid), average='macro'))\n",
        "print(classification_report(y_valid, xgb_prediction))"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "hIZYA_pXSTx6",
        "outputId": "445ccd6b-5b54-4598-e7e8-5e8e3494f7c5"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "word level tf-idf training score: 0.8909679680674745\n",
            "word level tf-idf validation score: 0.7637331832057742\n",
            "              precision    recall  f1-score   support\n",
            "\n",
            "           0       0.80      0.90      0.85     84355\n",
            "           1       0.78      0.61      0.68     49080\n",
            "\n",
            "    accuracy                           0.79    133435\n",
            "   macro avg       0.79      0.75      0.76    133435\n",
            "weighted avg       0.79      0.79      0.79    133435\n",
            "\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "#Calculating LogLoss to compare XGB with BOW and XGB with TF-IDF weighted word2vec\n",
        "from sklearn.metrics import accuracy_score, log_loss\n",
        "\n",
        "log_loss_test = log_loss(y_valid, xgb_model_1.predict(X_valid), eps=1e-15)\n",
        "print(\"log loss is\",log_loss_test)\n"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "M8EV12aCWc08",
        "outputId": "7e3024fb-7086-4dcb-d33d-c0bf425d77d0"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "log loss is 7.194864121231109\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "#TF-IDF at word level and with ngrams - XGBoost\n",
        "tfidf_vect_ngram = TfidfVectorizer(analyzer='word', token_pattern=r'\\w{1,}', ngram_range=(2,3), max_features=5000)\n",
        "tfidf_vect_ngram.fit(pd.concat((df_tfidf['question1'],df_tfidf['question2'])).unique())\n",
        "trainq1_trans = tfidf_vect_ngram.transform(df_tfidf['question1'].values)\n",
        "trainq2_trans = tfidf_vect_ngram.transform(df_tfidf['question2'].values)\n",
        "labels = df_tfidf['is_duplicate'].values\n",
        "X = scipy.sparse.hstack((trainq1_trans,trainq2_trans))\n",
        "y = labels\n",
        "X_train,X_valid,y_train,y_valid = train_test_split(X,y, test_size = 0.33, random_state = 42)\n",
        "\n",
        "xgb_model_2 = xgb.XGBClassifier(max_depth=50, n_estimators=80, learning_rate=0.1, colsample_bytree=.7, gamma=0, reg_alpha=4, objective='binary:logistic', eta=0.3, silent=1, subsample=0.8).fit(X_train, y_train) \n",
        "xgb_prediction = xgb_model_2.predict(X_valid)\n",
        "print('n-gram level tf-idf training score:', f1_score(y_train, xgb_model_2.predict(X_train), average='macro'))\n",
        "print('n-gram level tf-idf validation score:', f1_score(y_valid, xgb_model_2.predict(X_valid), average='macro'))\n",
        "print(classification_report(y_valid, xgb_prediction))"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "eglbFUXaH-fn",
        "outputId": "f9791f85-0f64-488c-cb01-b63981931654"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "n-gram level tf-idf training score: 0.7424796197136108\n",
            "n-gram level tf-idf validation score: 0.6788727792847618\n",
            "              precision    recall  f1-score   support\n",
            "\n",
            "           0       0.73      0.92      0.81     84355\n",
            "           1       0.75      0.43      0.54     49080\n",
            "\n",
            "    accuracy                           0.74    133435\n",
            "   macro avg       0.74      0.67      0.68    133435\n",
            "weighted avg       0.74      0.74      0.71    133435\n",
            "\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [],
      "metadata": {
        "id": "Qij-fOoPIcke"
      },
      "execution_count": null,
      "outputs": []
    }
  ]
}